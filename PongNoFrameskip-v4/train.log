Command line: train_atari.py --config config/Pong_ours.json
Namespace(config='config/Pong_ours.json', model_subset=None, path_prefix='', seed=2019, overrides=[], overrides_dict={})
/n
{'path_prefix': '', 'name_suffix': '', 'training_config': {'seed': 8, 'load_model_path': '', 'robust': False, 'dueling': True, 'adv_train': False, 'adv_ratio': 0.5, 'bound_solver': 'cov', 'attack_config': {'method': 'pgd', 'verbose': False, 'params': {'epsilon': 0.00392, 'niters': 5, 'img_min': 0.0, 'img_max': 1.0, 'random_start': True}}, 'hinge': True, 'hinge_c': 1, 'model_width': 1, 'act_epsilon_start': 1.0, 'act_epsilon_final': 0.05, 'act_epsilon_decay': 1500000, 'act_epsilon_method': 'linear', 'act_epsilon_decay_zero': True, 'num_frames': 6000000, 'env_params': {'frame_stack': False, 'color_image': False, 'central_crop': True, 'crop_shift': 10, 'restrict_actions': 4}, 'batch_size': 32, 'gamma': 0.99, 'lr': 2e-06, 'grad_clip': -1, 'natural_loss_fn': 'huber', 'adam_eps': 0.00015, 'save_frame': 5000, 'print_frame': 1000, 'update_target_frame': 2000, 'per': True, 'cpprb': True, 'show_game': False, 'record_game': False, 'use_async_env': True, 'use_async_rb': True, 'buffer_params': {'replay_initial': 10000, 'buffer_capacity': 200000, 'buffer_beta_start': 0.4, 'buffer_beta_frames': -1, 'alpha': 0.5}, 'convex_start_beta': 1.0, 'convex_final_beta': 0.0, 'start_epsilon': 0.0, 'epsilon': 0.00392, 'schedule_start': 1500000, 'schedule_length': 4000000, 'schedule_type': 'smoothed', 'mini_test': 100000, 'kappa': 0.005, 'ours': True}, 'test_config': {'load_model_path': '', 'log_name': 'test.log', 'num_episodes': 100, 'max_frames_per_episode': 1000, 'save_frames': False, 'print_frame': 100, 'attack': False, 'max_min': False, 'certify': False, 'attack_config': {'method': 'pgd', 'verbose': False, 'params': {'epsilon': 0.00392, 'niters': 10, 'img_min': 0.0, 'img_max': 1.0, 'random_start': True}}}, 'env_id': 'PongNoFrameskip-v4'}
env_shape: (1, 84, 84), num of actions: 4
action meaning: ['NOOP', 'FIRE', 'RIGHT', 'LEFT']
using cpp replay buffer
using prioritized experience replay.
beffer_beta_frames reset to  1990000
